{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acd70616",
   "metadata": {},
   "source": [
    "### Loading documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e870b74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrados 453 archivos PDF\n",
      "Cargando: CL22.pdf\n",
      "  ✓ Cargado: 14 páginas\n",
      "Cargando: IE157.pdf\n",
      "  ✓ Cargado: 7 páginas\n",
      "Cargando: AN14.pdf\n",
      "  ✓ Cargado: 13 páginas\n",
      "Cargando: L1.pdf\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m all_docs\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Cargar todos los documentos\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m docs = \u001b[43mload_pdfs_from_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_directory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m Resumen:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTotal de páginas cargadas: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mload_pdfs_from_directory\u001b[39m\u001b[34m(directory_path)\u001b[39m\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCargando: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.path.basename(pdf_file)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     29\u001b[39m loader = PyPDFLoader(pdf_file)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m docs = \u001b[43mloader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m all_docs.extend(docs)\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ Cargado: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(docs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m páginas\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/langchain_core/document_loaders/base.py:32\u001b[39m, in \u001b[36mBaseLoader.load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Document]:\n\u001b[32m     31\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Load data into Document objects.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlazy_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/langchain_community/document_loaders/pdf.py:305\u001b[39m, in \u001b[36mPyPDFLoader.lazy_load\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    303\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    304\u001b[39m     blob = Blob.from_path(\u001b[38;5;28mself\u001b[39m.file_path)\n\u001b[32m--> \u001b[39m\u001b[32m305\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.parser.lazy_parse(blob)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:396\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse\u001b[39m\u001b[34m(self, blob)\u001b[39m\n\u001b[32m    394\u001b[39m single_texts = []\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m page_number, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pdf_reader.pages):\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m     text_from_page = \u001b[43m_extract_text_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m     images_from_page = \u001b[38;5;28mself\u001b[39m.extract_images_from_page(page)\n\u001b[32m    398\u001b[39m     all_text = _merge_text_and_extras(\n\u001b[32m    399\u001b[39m         [images_from_page], text_from_page\n\u001b[32m    400\u001b[39m     ).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/langchain_community/document_loaders/parsers/pdf.py:378\u001b[39m, in \u001b[36mPyPDFParser.lazy_parse.<locals>._extract_text_from_page\u001b[39m\u001b[34m(page)\u001b[39m\n\u001b[32m    376\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m page.extract_text()\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mextraction_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/pypdf/_page.py:2350\u001b[39m, in \u001b[36mPageObject.extract_text\u001b[39m\u001b[34m(self, orientations, space_width, visitor_operand_before, visitor_operand_after, visitor_text, extraction_mode, *args, **kwargs)\u001b[39m\n\u001b[32m   2347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(orientations, \u001b[38;5;28mint\u001b[39m):\n\u001b[32m   2348\u001b[39m     orientations = (orientations,)\n\u001b[32m-> \u001b[39m\u001b[32m2350\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_extract_text\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2351\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2352\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2353\u001b[39m \u001b[43m    \u001b[49m\u001b[43morientations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspace_width\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPG\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCONTENTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_operand_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvisitor_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2359\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/pypdf/_page.py:2045\u001b[39m, in \u001b[36mPageObject._extract_text\u001b[39m\u001b[34m(self, obj, pdf, orientations, space_width, content_key, visitor_operand_before, visitor_operand_after, visitor_text)\u001b[39m\n\u001b[32m   2042\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m OrientationNotFoundError:\n\u001b[32m   2043\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2045\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m operands, operator \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcontent\u001b[49m\u001b[43m.\u001b[49m\u001b[43moperations\u001b[49m:\n\u001b[32m   2046\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m visitor_operand_before \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2047\u001b[39m         visitor_operand_before(operator, operands, cm_matrix, tm_matrix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/pypdf/generic/_data_structures.py:1422\u001b[39m, in \u001b[36mContentStream.operations\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1419\u001b[39m \u001b[38;5;129m@property\u001b[39m\n\u001b[32m   1420\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moperations\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> List[Tuple[Any, \u001b[38;5;28mbytes\u001b[39m]]:\n\u001b[32m   1421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._operations \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data:\n\u001b[32m-> \u001b[39m\u001b[32m1422\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_content_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1423\u001b[39m         \u001b[38;5;28mself\u001b[39m._data = \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1424\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._operations\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/pypdf/generic/_data_structures.py:1315\u001b[39m, in \u001b[36mContentStream._parse_content_stream\u001b[39m\u001b[34m(self, stream)\u001b[39m\n\u001b[32m   1313\u001b[39m         peek = stream.read(\u001b[32m1\u001b[39m)\n\u001b[32m   1314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1315\u001b[39m     operands.append(\u001b[43mread_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforced_encoding\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/pae/lib/python3.11/site-packages/pypdf/generic/_data_structures.py:1483\u001b[39m, in \u001b[36mread_object\u001b[39m\u001b[34m(stream, pdf, forced_encoding)\u001b[39m\n\u001b[32m   1481\u001b[39m peek = stream.read(\u001b[32m20\u001b[39m)\n\u001b[32m   1482\u001b[39m stream.seek(-\u001b[38;5;28mlen\u001b[39m(peek), \u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# reset to start\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1483\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mIndirectPattern\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpeek\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1484\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m pdf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mmypy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m IndirectObject.read_from_stream(stream, pdf)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Ruta a la carpeta que contiene los PDFs\n",
    "pdf_directory = \"/home/cristian/projects/rag_pae/data/pdfs/amazonica\"\n",
    "\n",
    "def load_pdfs_from_directory(directory_path):\n",
    "    \"\"\"Carga todos los PDFs de un directorio con manejo de errores\"\"\"\n",
    "    all_docs = []\n",
    "    \n",
    "    if not os.path.exists(directory_path):\n",
    "        print(f\"Error: La carpeta {directory_path} no existe\")\n",
    "        return all_docs\n",
    "    \n",
    "    # Obtener lista de archivos PDF\n",
    "    pdf_files = glob.glob(os.path.join(directory_path, \"*.pdf\"))\n",
    "    \n",
    "    if not pdf_files:\n",
    "        print(f\"No se encontraron archivos PDF en {directory_path}\")\n",
    "        return all_docs\n",
    "    \n",
    "    print(f\"Encontrados {len(pdf_files)} archivos PDF\")\n",
    "    \n",
    "    # Cargar cada PDF individualmente\n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            print(f\"Cargando: {os.path.basename(pdf_file)}\")\n",
    "            loader = PyPDFLoader(pdf_file)\n",
    "            docs = loader.load()\n",
    "            all_docs.extend(docs)\n",
    "            print(f\"  ✓ Cargado: {len(docs)} páginas\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ✗ Error cargando {os.path.basename(pdf_file)}: {e}\")\n",
    "    \n",
    "    return all_docs\n",
    "\n",
    "# Cargar todos los documentos\n",
    "docs = load_pdfs_from_directory(pdf_directory)\n",
    "\n",
    "print(f\"\\n Resumen:\")\n",
    "print(f\"Total de páginas cargadas: {len(docs)}\")\n",
    "\n",
    "# Mostrar información de algunos documentos\n",
    "if docs:\n",
    "    print(f\"\\n📄 Primeros documentos:\")\n",
    "    for i, doc in enumerate(docs[:5]):\n",
    "        source = os.path.basename(doc.metadata.get('source', 'Sin fuente'))\n",
    "        page = doc.metadata.get('page', 'N/A')\n",
    "        print(f\"  {i+1}. {source} (página {page}) - {len(doc.page_content)} caracteres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4f8b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83ee9499",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RecursiveCharacterTextSplitter\n\u001b[32m      5\u001b[39m text_splitter = RecursiveCharacterTextSplitter(chunk_size=\u001b[32m1000\u001b[39m, chunk_overlap=\u001b[32m200\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m splits = text_splitter.split_documents(\u001b[43mdocs\u001b[49m)\n\u001b[32m      7\u001b[39m embeddings = OllamaEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mnomic-embed-text\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m vectorstore = Chroma.from_documents(documents=splits, embedding= embeddings, persist_directory=\u001b[33m\"\u001b[39m\u001b[33mchroma_db\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'docs' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding= embeddings, persist_directory=\"chroma_db\")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe77c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "results = rag_chain.invoke({\"input\": \"\"\"\n",
    "\n",
    " ¿De qué trata el foro con el título \"Notas para una aproximación a la dinámica del conflicto armado en El Catatumbo?\n",
    "\n",
    "\"\"\"})\n",
    "\n",
    "results['answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4936b8e",
   "metadata": {},
   "source": [
    "### Using RAG Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fcb9423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La isla de San Andrés ha experimentado una creolización de la violencia debido a su contexto único, donde los habitantes se sienten constantemente amenazados por la violencia y el narcotráfico. Esto ha llevado a la juventud a generar propuestas para combatir la violencia a través de la cultura. \n",
      "\n",
      "La isla está rodeada de noticias violentas y sus habitantes sobredimensionan los efectos, lo que ha llevado a una creolización de la violencia como parte de su identidad.\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings, OllamaLLM\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Cargar la base de datos vectorial existente\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "vectorstore = Chroma(persist_directory=\"/home/cristian/projects/rag_pae/chroma_db\", embedding_function=embeddings)\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "# Configurar el LLM\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Configurar el prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"Use line breaks to separte the sentences.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Crear las cadenas RAG\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "# Usar el RAG - ejemplo\n",
    "results = rag_chain.invoke({\n",
    "    \"input\": \"dame un resumen Una isla a la deriva: creolización de la violencia en la isla de San Andrés\"\n",
    "})\n",
    "\n",
    "print(results['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
